{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOG+DTL3/lv3m5kktsdsBP5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aakhterov/ML_projects/blob/master/machine_translation/machine_translation_with_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrOij2Lsj3yA",
        "outputId": "21435abb-4660-4fa6-89c7-06bc48a964a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from typing import List\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from pprint import pprint\n",
        "from string import punctuation\n",
        "from tensorflow.keras.layers import TextVectorization, Embedding, LSTM, Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UNKNOWN_TOKEN = '[UNK]'\n",
        "START_TOKEN = '[START]'\n",
        "END_TOKEN = '[END]'"
      ],
      "metadata": {
        "id": "_RSzJxTxSmLY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Vectorization:\n",
        "\n",
        "  def __init__(self,\n",
        "               max_tokens,\n",
        "               max_length=None,\n",
        "               unknown_token=UNKNOWN_TOKEN,\n",
        "               start_token=START_TOKEN,\n",
        "               end_token=END_TOKEN\n",
        "               ):\n",
        "\n",
        "    self.max_tokens = max_tokens\n",
        "    self.max_length = max_length\n",
        "    self.unknown_token = unknown_token\n",
        "    self.start_token = start_token\n",
        "    self.end_token=end_token\n",
        "    self.vocabulary = ['', self.unknown_token, self.start_token, self.end_token]\n",
        "\n",
        "  def __preprocessing(self, input: str) -> str:\n",
        "    output = ''.join(map(lambda ch: ch if ch not in punctuation else ' ', input.lower())).strip()\n",
        "    return output\n",
        "\n",
        "  def token_to_text(self, tokens: List) -> str:\n",
        "    words = [self.vocabulary[token] for token in tokens]\n",
        "    return \" \".join(words)\n",
        "\n",
        "  def fit(self, X: List):\n",
        "      lens = []\n",
        "      for x in X:\n",
        "        words = self.__preprocessing(x).split()\n",
        "        lens.append(len(words))\n",
        "        for word in words:\n",
        "          token = word.strip()\n",
        "          if token not in self.vocabulary and self.max_tokens is not None and len(self.vocabulary)<self.max_tokens:\n",
        "            self.vocabulary.append(token)\n",
        "      lens = np.array(lens)\n",
        "      if self.max_length is None:\n",
        "        self.max_length = int(np.mean(lens) + 2 * np.std(lens))\n",
        "      return self\n",
        "\n",
        "  def predict(self,\n",
        "              X: List,\n",
        "              is_padding=True,\n",
        "              is_add_start_token=False,\n",
        "              is_add_end_token=False\n",
        "              ) -> List[List]:\n",
        "    output = []\n",
        "    for x in X:\n",
        "\n",
        "      vector = [self.vocabulary.index(self.start_token)] if is_add_start_token else []\n",
        "\n",
        "      for word in self.__preprocessing(x).split():\n",
        "        token = word.strip()\n",
        "        vector.append(self.vocabulary.index(token) if token in self.vocabulary else self.vocabulary.index(self.unknown_token))\n",
        "\n",
        "      vector = vector[:self.max_length-1]\n",
        "      if is_add_end_token:\n",
        "        vector.append(self.vocabulary.index(self.end_token))\n",
        "\n",
        "      output.append(vector)\n",
        "    return pad_sequences(output,\n",
        "                         maxlen=self.max_length,\n",
        "                         padding='post',\n",
        "                         truncating='post') if is_padding else output"
      ],
      "metadata": {
        "id": "OwlrS_c8K6pU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_phrases, output_phrases = [], []\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Data/rus.txt') as f:\n",
        "  for line in f.readlines()[:10_000]:\n",
        "    x, y = line.split('CC-BY')[0].strip().split('\\t')\n",
        "    input_phrases.append(x)\n",
        "    output_phrases.append(y)"
      ],
      "metadata": {
        "id": "VvaCDzcFuIe1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_vocab = 10_000\n",
        "output_vocab = 10_000\n",
        "# max_length = 30"
      ],
      "metadata": {
        "id": "d-LhZGvyvrkS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_vec = Vectorization(max_tokens=input_vocab)\n",
        "encoder_vec.fit(input_phrases)\n",
        "X_encoder = encoder_vec.predict(input_phrases)\n",
        "\n",
        "decoder_vec = Vectorization(max_tokens=output_vocab)\n",
        "decoder_vec.fit(output_phrases)\n",
        "X_decoder = decoder_vec.predict(output_phrases, is_add_start_token=True, is_add_end_token=True)\n",
        "Y_decoder = decoder_vec.predict(output_phrases, is_add_end_token=True)"
      ],
      "metadata": {
        "id": "chd-W_mXVgqE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 1\n",
        "print(f\"Index: {idx}\")\n",
        "print(\"======= Encoder =======\")\n",
        "print(f\"Input phrase: {input_phrases[idx]}\")\n",
        "print(f\"Vector: {X_encoder[idx]}\")\n",
        "print(\"======= Decoder =======\")\n",
        "print(f\"Input phrase: {output_phrases[idx]}\")\n",
        "print(f\"Vector: {X_decoder[idx]}\")\n",
        "print(f\"Output phrase: {output_phrases[idx]}\")\n",
        "print(f\"Vector: {Y_decoder[idx]}\")\n",
        "print(\"==============\")\n",
        "print(f\"Start phrase token index: {decoder_vec.vocabulary.index(START_TOKEN)}\")\n",
        "print(f\"End phrase token index: {decoder_vec.vocabulary.index(END_TOKEN)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHSeTSRGQhmS",
        "outputId": "4ecc2218-263c-4c26-e038-2ef82226041e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 1\n",
            "======= Encoder =======\n",
            "Input phrase: Go.\n",
            "Vector: [4 0 0 0]\n",
            "======= Decoder =======\n",
            "Input phrase: Иди.\n",
            "Vector: [2 5 3 0]\n",
            "Output phrase: Иди.\n",
            "Vector: [5 3 0 0]\n",
            "==============\n",
            "Start phrase token index: 2\n",
            "End phrase token index: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, X_test, y_train, y_test  = train_test_split(np.array(list(zip(X_encoder, X_decoder))), np.array(Y_decoder), train_size = 0.8)"
      ],
      "metadata": {
        "id": "JM_X6hXkVfJY"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = Input(shape=(None, ),\n",
        "                      name='encoder_input')\n",
        "encoder_emedding = Embedding(input_dim=input_vocab,\n",
        "                             output_dim=64,\n",
        "                             mask_zero=True,\n",
        "                             name='encoder_embedding')\n",
        "encoder_lstm = LSTM(units=128,\n",
        "                    return_state=True,\n",
        "                    name='encoder_lstm')\n",
        "\n",
        "decoder_input = Input(shape=(None, ),\n",
        "                      name='decoder_input')\n",
        "decoder_initial_h_state = Input(shape=(None, ),\n",
        "                                name='decoder_initial_h_state')\n",
        "decoder_initial_c_state = Input(shape=(None, ),\n",
        "                                name='decoder_initial_c_state')\n",
        "decoder_emedding = Embedding(input_dim=output_vocab,\n",
        "                             output_dim=64,\n",
        "                             mask_zero=True,\n",
        "                             name='decoder_embedding')\n",
        "decoder_lstm= LSTM(units=128,\n",
        "                   return_sequences=True,\n",
        "                   return_state=True,\n",
        "                   name='decoder_lstm')\n",
        "decoder_dense = Dense(units=output_vocab,\n",
        "                      activation='softmax',\n",
        "                      name='decoder_output')"
      ],
      "metadata": {
        "id": "IAvOW5QU3p-U"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_net(encoder_input):\n",
        "  out = encoder_emedding(encoder_input)\n",
        "  _, h, c = encoder_lstm(out)\n",
        "  return h, c\n",
        "\n",
        "def decoder_net(decoder_input, decoder_initial_state):\n",
        "  out = decoder_emedding(decoder_input)\n",
        "  out, _, _ = decoder_lstm(out, initial_state=decoder_initial_state)\n",
        "  out = decoder_dense(out)\n",
        "  return out"
      ],
      "metadata": {
        "id": "Fx8aXltXUEwG"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_state = encoder_net(encoder_input=encoder_input)\n",
        "\n",
        "decoder_connected_to_encoder_output = decoder_net(decoder_input=decoder_input,\n",
        "                                                  decoder_initial_state=encoder_state)"
      ],
      "metadata": {
        "id": "1-raJJ0GX_cx"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_train = Model(inputs=[encoder_input, decoder_input], outputs=decoder_connected_to_encoder_output)\n",
        "model_train.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x91F1g68dFrX",
        "outputId": "9807071c-6484-4e5f-d21f-7be7b47d1be3"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)  [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " decoder_input (InputLayer)  [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " encoder_embedding (Embeddi  (None, None, 64)             640000    ['encoder_input[0][0]']       \n",
            " ng)                                                                                              \n",
            "                                                                                                  \n",
            " decoder_embedding (Embeddi  (None, None, 64)             640000    ['decoder_input[0][0]']       \n",
            " ng)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_lstm (LSTM)         [(None, 128),                98816     ['encoder_embedding[0][0]']   \n",
            "                              (None, 128),                                                        \n",
            "                              (None, 128)]                                                        \n",
            "                                                                                                  \n",
            " decoder_lstm (LSTM)         multiple                     98816     ['decoder_embedding[0][0]',   \n",
            "                                                                     'encoder_lstm[0][1]',        \n",
            "                                                                     'encoder_lstm[0][2]']        \n",
            "                                                                                                  \n",
            " decoder_output (Dense)      (None, None, 10000)          1290000   ['decoder_lstm[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2767632 (10.56 MB)\n",
            "Trainable params: 2767632 (10.56 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_train.compile(\n",
        "    loss=SparseCategoricalCrossentropy(),\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "id": "hUcHWWeveNoZ"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = {\n",
        "    'encoder_input': X_encoder,\n",
        "    'decoder_input': X_decoder\n",
        "}\n",
        "\n",
        "y_data = {\n",
        "    'decoder_output': Y_decoder\n",
        "}"
      ],
      "metadata": {
        "id": "hmVbacDce0DT"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_train.fit(\n",
        "    x = x_data,\n",
        "    y = y_data,\n",
        "    validation_split = 0.2,\n",
        "    batch_size=64,\n",
        "    epochs=50\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vIXHvX7g391",
        "outputId": "481ffc74-7920-4ac8-e3e5-15f4b81bc7b3"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "125/125 [==============================] - 31s 187ms/step - loss: 4.0366 - accuracy: 0.3801 - val_loss: 4.5762 - val_accuracy: 0.3745\n",
            "Epoch 2/50\n",
            "125/125 [==============================] - 22s 172ms/step - loss: 3.5532 - accuracy: 0.4749 - val_loss: 4.5127 - val_accuracy: 0.3938\n",
            "Epoch 3/50\n",
            "125/125 [==============================] - 20s 159ms/step - loss: 3.2740 - accuracy: 0.5085 - val_loss: 4.3656 - val_accuracy: 0.4177\n",
            "Epoch 4/50\n",
            "125/125 [==============================] - 23s 185ms/step - loss: 3.0446 - accuracy: 0.5307 - val_loss: 4.3210 - val_accuracy: 0.4392\n",
            "Epoch 5/50\n",
            "125/125 [==============================] - 20s 163ms/step - loss: 2.8400 - accuracy: 0.5534 - val_loss: 4.2576 - val_accuracy: 0.4683\n",
            "Epoch 6/50\n",
            "125/125 [==============================] - 24s 189ms/step - loss: 2.6665 - accuracy: 0.5701 - val_loss: 4.2026 - val_accuracy: 0.4864\n",
            "Epoch 7/50\n",
            "125/125 [==============================] - 21s 172ms/step - loss: 2.5129 - accuracy: 0.5841 - val_loss: 4.1974 - val_accuracy: 0.4916\n",
            "Epoch 8/50\n",
            "125/125 [==============================] - 24s 192ms/step - loss: 2.3804 - accuracy: 0.5925 - val_loss: 4.2510 - val_accuracy: 0.4880\n",
            "Epoch 9/50\n",
            "125/125 [==============================] - 21s 165ms/step - loss: 2.2612 - accuracy: 0.6022 - val_loss: 4.2080 - val_accuracy: 0.4976\n",
            "Epoch 10/50\n",
            "125/125 [==============================] - 22s 176ms/step - loss: 2.1514 - accuracy: 0.6115 - val_loss: 4.1945 - val_accuracy: 0.5017\n",
            "Epoch 11/50\n",
            "125/125 [==============================] - 21s 169ms/step - loss: 2.0502 - accuracy: 0.6209 - val_loss: 4.2445 - val_accuracy: 0.4989\n",
            "Epoch 12/50\n",
            "125/125 [==============================] - 21s 168ms/step - loss: 1.9552 - accuracy: 0.6293 - val_loss: 4.2342 - val_accuracy: 0.5075\n",
            "Epoch 13/50\n",
            "125/125 [==============================] - 22s 176ms/step - loss: 1.8648 - accuracy: 0.6406 - val_loss: 4.2365 - val_accuracy: 0.5063\n",
            "Epoch 14/50\n",
            "125/125 [==============================] - 20s 164ms/step - loss: 1.7828 - accuracy: 0.6473 - val_loss: 4.2573 - val_accuracy: 0.5063\n",
            "Epoch 15/50\n",
            "125/125 [==============================] - 23s 183ms/step - loss: 1.7039 - accuracy: 0.6551 - val_loss: 4.3288 - val_accuracy: 0.5063\n",
            "Epoch 16/50\n",
            "125/125 [==============================] - 21s 169ms/step - loss: 1.6263 - accuracy: 0.6620 - val_loss: 4.2999 - val_accuracy: 0.5101\n",
            "Epoch 17/50\n",
            "125/125 [==============================] - 23s 185ms/step - loss: 1.5568 - accuracy: 0.6697 - val_loss: 4.3454 - val_accuracy: 0.5099\n",
            "Epoch 18/50\n",
            "125/125 [==============================] - 21s 169ms/step - loss: 1.4893 - accuracy: 0.6791 - val_loss: 4.3423 - val_accuracy: 0.5134\n",
            "Epoch 19/50\n",
            "125/125 [==============================] - 23s 182ms/step - loss: 1.4262 - accuracy: 0.6861 - val_loss: 4.4109 - val_accuracy: 0.5076\n",
            "Epoch 20/50\n",
            "125/125 [==============================] - 20s 163ms/step - loss: 1.3665 - accuracy: 0.6933 - val_loss: 4.3762 - val_accuracy: 0.5105\n",
            "Epoch 21/50\n",
            "125/125 [==============================] - 22s 176ms/step - loss: 1.3107 - accuracy: 0.7031 - val_loss: 4.4631 - val_accuracy: 0.5043\n",
            "Epoch 22/50\n",
            "125/125 [==============================] - 21s 170ms/step - loss: 1.2564 - accuracy: 0.7076 - val_loss: 4.3989 - val_accuracy: 0.5087\n",
            "Epoch 23/50\n",
            "125/125 [==============================] - 20s 164ms/step - loss: 1.2061 - accuracy: 0.7165 - val_loss: 4.4523 - val_accuracy: 0.5087\n",
            "Epoch 24/50\n",
            "125/125 [==============================] - 22s 176ms/step - loss: 1.1572 - accuracy: 0.7240 - val_loss: 4.4901 - val_accuracy: 0.5139\n",
            "Epoch 25/50\n",
            "125/125 [==============================] - 20s 161ms/step - loss: 1.1125 - accuracy: 0.7304 - val_loss: 4.4972 - val_accuracy: 0.5135\n",
            "Epoch 26/50\n",
            "125/125 [==============================] - 22s 180ms/step - loss: 1.0701 - accuracy: 0.7356 - val_loss: 4.5088 - val_accuracy: 0.5141\n",
            "Epoch 27/50\n",
            "125/125 [==============================] - 21s 167ms/step - loss: 1.0291 - accuracy: 0.7432 - val_loss: 4.5181 - val_accuracy: 0.5140\n",
            "Epoch 28/50\n",
            "125/125 [==============================] - 22s 177ms/step - loss: 0.9886 - accuracy: 0.7499 - val_loss: 4.5333 - val_accuracy: 0.5161\n",
            "Epoch 29/50\n",
            "125/125 [==============================] - 21s 165ms/step - loss: 0.9500 - accuracy: 0.7559 - val_loss: 4.5762 - val_accuracy: 0.5158\n",
            "Epoch 30/50\n",
            "125/125 [==============================] - 21s 165ms/step - loss: 0.9151 - accuracy: 0.7602 - val_loss: 4.5953 - val_accuracy: 0.5136\n",
            "Epoch 31/50\n",
            "125/125 [==============================] - 22s 173ms/step - loss: 0.8812 - accuracy: 0.7652 - val_loss: 4.6082 - val_accuracy: 0.5109\n",
            "Epoch 32/50\n",
            "125/125 [==============================] - 20s 161ms/step - loss: 0.8498 - accuracy: 0.7718 - val_loss: 4.6348 - val_accuracy: 0.5090\n",
            "Epoch 33/50\n",
            "125/125 [==============================] - 22s 176ms/step - loss: 0.8193 - accuracy: 0.7770 - val_loss: 4.6475 - val_accuracy: 0.5107\n",
            "Epoch 34/50\n",
            "125/125 [==============================] - 20s 161ms/step - loss: 0.7924 - accuracy: 0.7803 - val_loss: 4.6515 - val_accuracy: 0.5171\n",
            "Epoch 35/50\n",
            "125/125 [==============================] - 24s 192ms/step - loss: 0.7637 - accuracy: 0.7842 - val_loss: 4.6981 - val_accuracy: 0.5144\n",
            "Epoch 36/50\n",
            "125/125 [==============================] - 20s 159ms/step - loss: 0.7388 - accuracy: 0.7887 - val_loss: 4.7145 - val_accuracy: 0.5115\n",
            "Epoch 37/50\n",
            "125/125 [==============================] - 21s 168ms/step - loss: 0.7146 - accuracy: 0.7934 - val_loss: 4.6974 - val_accuracy: 0.5210\n",
            "Epoch 38/50\n",
            "125/125 [==============================] - 20s 162ms/step - loss: 0.6920 - accuracy: 0.7952 - val_loss: 4.7435 - val_accuracy: 0.5122\n",
            "Epoch 39/50\n",
            "125/125 [==============================] - 20s 157ms/step - loss: 0.6698 - accuracy: 0.8002 - val_loss: 4.7384 - val_accuracy: 0.5135\n",
            "Epoch 40/50\n",
            "125/125 [==============================] - 21s 169ms/step - loss: 0.6506 - accuracy: 0.8009 - val_loss: 4.7471 - val_accuracy: 0.5156\n",
            "Epoch 41/50\n",
            "125/125 [==============================] - 20s 163ms/step - loss: 0.6308 - accuracy: 0.8054 - val_loss: 4.8102 - val_accuracy: 0.5176\n",
            "Epoch 42/50\n",
            "125/125 [==============================] - 20s 164ms/step - loss: 0.6142 - accuracy: 0.8065 - val_loss: 4.7879 - val_accuracy: 0.5116\n",
            "Epoch 43/50\n",
            "125/125 [==============================] - 22s 175ms/step - loss: 0.5979 - accuracy: 0.8090 - val_loss: 4.8061 - val_accuracy: 0.5214\n",
            "Epoch 44/50\n",
            "125/125 [==============================] - 20s 164ms/step - loss: 0.5809 - accuracy: 0.8103 - val_loss: 4.8282 - val_accuracy: 0.5139\n",
            "Epoch 45/50\n",
            "125/125 [==============================] - 22s 178ms/step - loss: 0.5653 - accuracy: 0.8127 - val_loss: 4.8416 - val_accuracy: 0.5180\n",
            "Epoch 46/50\n",
            "125/125 [==============================] - 21s 166ms/step - loss: 0.5526 - accuracy: 0.8128 - val_loss: 4.8247 - val_accuracy: 0.5168\n",
            "Epoch 47/50\n",
            "125/125 [==============================] - 22s 177ms/step - loss: 0.5390 - accuracy: 0.8148 - val_loss: 4.8862 - val_accuracy: 0.5166\n",
            "Epoch 48/50\n",
            "125/125 [==============================] - 21s 165ms/step - loss: 0.5264 - accuracy: 0.8170 - val_loss: 4.8638 - val_accuracy: 0.5130\n",
            "Epoch 49/50\n",
            "125/125 [==============================] - 21s 170ms/step - loss: 0.5158 - accuracy: 0.8169 - val_loss: 4.8928 - val_accuracy: 0.5136\n",
            "Epoch 50/50\n",
            "125/125 [==============================] - 21s 168ms/step - loss: 0.5036 - accuracy: 0.8188 - val_loss: 4.8811 - val_accuracy: 0.5166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_train.save_weights('/content/drive/MyDrive/Colab Notebooks/Data/machine_translation_encoder_decoder_weights.h5')"
      ],
      "metadata": {
        "id": "hFchWp3nIPwK"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_output = decoder_net(decoder_input=decoder_input,\n",
        "                             decoder_initial_state=[decoder_initial_h_state, decoder_initial_c_state])"
      ],
      "metadata": {
        "id": "iHJ4kLh8ew9k"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_encoder_prediction = Model(inputs=encoder_input, outputs=encoder_state)\n",
        "model_encoder_prediction.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq8Cyz-YeGYN",
        "outputId": "18eb43ef-e10e-4171-b51f-20509eedb0e2"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_input (InputLayer)  [(None, None)]            0         \n",
            "                                                                 \n",
            " encoder_embedding (Embeddi  (None, None, 64)          640000    \n",
            " ng)                                                             \n",
            "                                                                 \n",
            " encoder_lstm (LSTM)         [(None, 128),             98816     \n",
            "                              (None, 128),                       \n",
            "                              (None, 128)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 738816 (2.82 MB)\n",
            "Trainable params: 738816 (2.82 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_decoder_prediction = Model(inputs=[decoder_input, decoder_initial_h_state, decoder_initial_c_state],\n",
        "                                 outputs=decoder_output)\n",
        "model_decoder_prediction.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok6xj9I0eGfx",
        "outputId": "61ce3c17-9225-49ac-db8d-279f42690e8a"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " decoder_input (InputLayer)  [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " decoder_embedding (Embeddi  (None, None, 64)             640000    ['decoder_input[0][0]']       \n",
            " ng)                                                                                              \n",
            "                                                                                                  \n",
            " decoder_initial_h_state (I  [(None, None)]               0         []                            \n",
            " nputLayer)                                                                                       \n",
            "                                                                                                  \n",
            " decoder_initial_c_state (I  [(None, None)]               0         []                            \n",
            " nputLayer)                                                                                       \n",
            "                                                                                                  \n",
            " decoder_lstm (LSTM)         multiple                     98816     ['decoder_embedding[2][0]',   \n",
            "                                                                     'decoder_initial_h_state[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'decoder_initial_c_state[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " decoder_output (Dense)      (None, None, 10000)          1290000   ['decoder_lstm[2][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2028816 (7.74 MB)\n",
            "Trainable params: 2028816 (7.74 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text: str) -> str:\n",
        "  tokens = encoder_vec.predict([text])\n",
        "  max_length = encoder_vec.max_length\n",
        "\n",
        "  encoder_state = model_encoder_prediction.predict(tokens)\n",
        "\n",
        "  decoder_input = np.zeros((1, max_length), dtype=np.int16)\n",
        "  current_token = decoder_vec.vocabulary.index(START_TOKEN)\n",
        "  count_tokens = 0\n",
        "  output = []\n",
        "\n",
        "  while current_token != decoder_vec.vocabulary.index(END_TOKEN) and count_tokens < max_length:\n",
        "    decoder_input[0, count_tokens] = current_token\n",
        "    x_data = {\n",
        "        'decoder_input': decoder_input,\n",
        "        'decoder_initial_h_state': encoder_state[0],\n",
        "        'decoder_initial_c_state': encoder_state[1]\n",
        "    }\n",
        "    decoder_output = model_decoder_prediction.predict(x_data)\n",
        "    current_token = np.argmax(decoder_output[0, count_tokens, :])\n",
        "    count_tokens += 1\n",
        "\n",
        "    word = decoder_vec.vocabulary[current_token]\n",
        "\n",
        "    output.append(word)\n",
        "\n",
        "  return ' '.join(output[:-1])"
      ],
      "metadata": {
        "id": "eLUJbt6NeNt3"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict('i ran')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "vhWpXZTRklh4",
        "outputId": "f27b0b2a-6fa8-42c1-95e6-35343a502db9"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'я бежала'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jEIEkS5Fkllv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cxMVzNhUeGi-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}