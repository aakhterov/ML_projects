{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation, Input, Dropout\n",
    "from tensorflow.keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, vectors = [], []\n",
    "with open(\"data/metadata_norm_sentence_length_6_256_v2.tsv\", mode=\"r\") as words_file, \\\n",
    "open(\"data/vectors_norm_sentence_length_6_256_v2.tsv\", mode=\"r\") as vectors_file:\n",
    "    for word in words_file:\n",
    "        if not word.strip():\n",
    "            continue\n",
    "        words.append(word.strip())\n",
    "    for vector in vectors_file:\n",
    "        if not vector.strip():\n",
    "            continue\n",
    "        vectors.append([float(vec) for vec in vector.strip().split()]) \n",
    "\n",
    "embedding = {word: vectors[idx] for idx, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK = '[UNK]'\n",
    "sentence_length = 8\n",
    "embedding_vectors_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "samples = {}\n",
    "filename = \"data/multiclassification_dataset_new.csv\"\n",
    "with open(filename, mode=\"r\") as file:\n",
    "    for line in file:\n",
    "        sample, class_ = line[:-1].split(\";\")\n",
    "        class_ = \"_\".join(class_.split())\n",
    "        if class_ not in result:\n",
    "            result[class_] = []\n",
    "            samples[class_] = []\n",
    "        samples[class_].append(sample)\n",
    "        sentence_vector = []\n",
    "        words = sample.strip().split()[:sentence_length]\n",
    "        for word in words:\n",
    "            sentence_vector.append(embedding[word] if word in embedding else embedding[UNK])\n",
    "        if len(sentence_vector) < sentence_length:\n",
    "            for _ in range(sentence_length-len(sentence_vector)):\n",
    "                sentence_vector.append(embedding_vectors_dim*[0]) \n",
    "        if words:    \n",
    "            result[class_].append(sentence_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['connect_to_inet', 'no_internet', 'finance', 'support', 'consult'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(Y, C):\n",
    "    Y = np.eye(C, dtype=np.int)[Y.reshape(-1)]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "classes = list(result.keys())\n",
    "for class_, samples in result.items():    \n",
    "    for sample in samples:\n",
    "        X.append(sample)\n",
    "        y.append(classes.index(class_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y_oh = one_hot_encoder(np.array(y), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_oh, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5588, 8, 256), (5588, 5), (1398, 8, 256), (1398, 5))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassificationLSTMModel(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    X = LSTM(units=128)(inputs)\n",
    "    X = Dropout(rate=0.5)(X)\n",
    "    X = Dense(units=5)(X)\n",
    "    X = Activation('softmax')(X)\n",
    "    model = Model(inputs=inputs, outputs=X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 8, 256)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 197,765\n",
      "Trainable params: 197,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ClassificationLSTMModel((sentence_length, embedding_vectors_dim))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 2s 7ms/step - loss: 0.9587 - accuracy: 0.6455\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.4015 - accuracy: 0.8633\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.3231 - accuracy: 0.8926\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.2509 - accuracy: 0.9204\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.2310 - accuracy: 0.9289\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.2025 - accuracy: 0.9385\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.1711 - accuracy: 0.9468\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.1444 - accuracy: 0.9555\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.1262 - accuracy: 0.9602\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.1007 - accuracy: 0.9720\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.0894 - accuracy: 0.9710\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.0803 - accuracy: 0.9754\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.0675 - accuracy: 0.9744\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.0778 - accuracy: 0.9745\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.0659 - accuracy: 0.9779\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.0602 - accuracy: 0.9805\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.0621 - accuracy: 0.9786\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.0935 - accuracy: 0.9725\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 1s 8ms/step - loss: 0.0565 - accuracy: 0.9838\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 1s 8ms/step - loss: 0.0502 - accuracy: 0.9842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9c2cf83fd0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.9092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4552132487297058, 0.9091559648513794]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       124\n",
      "           1       0.87      0.81      0.84        96\n",
      "           2       0.93      0.94      0.94       374\n",
      "           3       0.92      0.94      0.93       369\n",
      "           4       0.91      0.88      0.90       435\n",
      "\n",
      "    accuracy                           0.91      1398\n",
      "   macro avg       0.89      0.89      0.89      1398\n",
      "weighted avg       0.91      0.91      0.91      1398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test_pred, axis=1), np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
