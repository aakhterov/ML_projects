{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTvFeXTfz5SrgE/0jsZD0b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aakhterov/ML_projects/blob/master/Text_classification/word2vec_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yrL2idXZ8OT",
        "outputId": "70f7057f-c408-4181-beb4-f977da0abb17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import tqdm\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "metadata": {
        "id": "lqPFJRv28lHC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_ns = 4 # Number of negative samples per target word"
      ],
      "metadata": {
        "id": "TWHwl-RM-mOG"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Данное устройство уже было ранее зарегистрированно в нашей сети\" # example\n",
        "tokens = list(sentence.lower().split())\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjyyK0RY8mC5",
        "outputId": "f04b2242-c23b-46a3-9124-dac9ade9d10b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['данное', 'устройство', 'уже', 'было', 'ранее', 'зарегистрированно', 'в', 'нашей', 'сети']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make vocabulary and inverse vocabulary"
      ],
      "metadata": {
        "id": "AOnlfAh-8yMN"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab, inverse_vocab = {'<pad>': 0}, {0: '<pad>'}\n",
        "for i, token in enumerate(tokens):\n",
        "    vocab[token] = vocab.get(token, i+1)\n",
        "    inverse_vocab[i+1] = token\n",
        "vocab_size = len(vocab)\n",
        "print(\"vocab:\", vocab)\n",
        "print(\"inverse_vocab:\", inverse_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_A-enJW8zPY",
        "outputId": "c52e788e-6e79-4dcf-b72f-36b42d0e9c90"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab: {'<pad>': 0, 'данное': 1, 'устройство': 2, 'уже': 3, 'было': 4, 'ранее': 5, 'зарегистрированно': 6, 'в': 7, 'нашей': 8, 'сети': 9}\n",
            "inverse_vocab: {0: '<pad>', 1: 'данное', 2: 'устройство', 3: 'уже', 4: 'было', 5: 'ранее', 6: 'зарегистрированно', 7: 'в', 8: 'нашей', 9: 'сети'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_sequence = [vocab[word] for word in tokens] # example encoded as a list of word indices\n",
        "print(example_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JnAFHcf82aZ",
        "outputId": "ee881ced-220e-4a16-ba9f-32e4bdadb4d0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating skip-grams - (word, word in the same window) with label 1 (positive samples);\n",
        "# (word, random word from the vocabulary), with label 0 (negative samples).\n",
        "# Context word is taken from the window of size - window_size"
      ],
      "metadata": {
        "id": "p7wiQyhQ82fa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 2\n",
        "skip_grams, labels = tf.keras.preprocessing.sequence.skipgrams(\n",
        "      example_sequence,\n",
        "      vocabulary_size=vocab_size,\n",
        "      window_size=window_size,\n",
        "      negative_samples=num_ns)"
      ],
      "metadata": {
        "id": "DcsITUBfEJ9q"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at labels, skip_grams and corresponding them pair of words"
      ],
      "metadata": {
        "id": "4CBPr0qPkHqJ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, skip_gram in enumerate(skip_grams[:10]):\n",
        "  print(f\"{labels[idx]}: {skip_gram} {inverse_vocab[skip_gram[0]]} {inverse_vocab[skip_gram[1]]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYkqTlFo82i6",
        "outputId": "4179efd6-ccbd-4e07-87aa-f9163cb6248a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: [5, 5] ранее ранее\n",
            "0: [7, 7] в в\n",
            "0: [3, 9] уже сети\n",
            "0: [2, 5] устройство ранее\n",
            "0: [7, 6] в зарегистрированно\n",
            "0: [9, 3] сети уже\n",
            "1: [5, 3] ранее уже\n",
            "0: [5, 9] ранее сети\n",
            "0: [6, 7] зарегистрированно в\n",
            "0: [2, 1] устройство данное\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We see there are skipgrams that should be positive, but they are negative instead (ex. [2, 1]). It's because of small vocabularity size.\n",
        "# Let's make vokab_size = 10000"
      ],
      "metadata": {
        "id": "BujV-u7xQnpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skip_grams, labels = tf.keras.preprocessing.sequence.skipgrams(\n",
        "      example_sequence,\n",
        "      vocabulary_size=10000,\n",
        "      window_size=window_size,\n",
        "      negative_samples=num_ns)"
      ],
      "metadata": {
        "id": "MwWFuXwGOkJX"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at one positive skipgram and coresponding negative skip grams"
      ],
      "metadata": {
        "id": "oA6yF-SNR5nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_skip_grams = [skip_gram for idx, skip_gram in enumerate(skip_grams) if labels[idx]==1]\n",
        "negative_skip_grams = [skip_gram for idx, skip_gram in enumerate(skip_grams) if labels[idx]==0]\n",
        "target_word, context_word = positive_skip_grams[0]\n",
        "\n",
        "negative_skip_grams_candidates = [skip_gram for skip_gram in negative_skip_grams if skip_gram[0]==target_word]\n",
        "current_negative_skip_grams = negative_skip_grams_candidates[:num_ns]"
      ],
      "metadata": {
        "id": "SSP8k2JiFMqV"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"target word: \", target_word)\n",
        "print(\"context word: \", context_word)\n",
        "print(\"current_negative_skip_grams: \", current_negative_skip_grams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miuBU-agRiN2",
        "outputId": "55d2a6ca-418b-4298-cff1-1f93d2e62145"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target word:  6\n",
            "context word:  5\n",
            "current_negative_skip_grams:  [[6, 5586], [6, 4499], [6, 995], [6, 6654]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... and convert target_word, context and labels to tf.Tensor"
      ],
      "metadata": {
        "id": "ygHE8YnfSgtQ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = tf.squeeze(target_word)\n",
        "context = tf.squeeze([context_word] + [x[1] for x in current_negative_skip_grams] )\n",
        "label = tf.constant([1] + [0]*num_ns)\n",
        "print(target)\n",
        "print(context)\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwJpcbQiZEvb",
        "outputId": "56be0384-643f-4d9b-c06e-77d7aaf50d58"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor([   5 5586 4499  995 6654], shape=(5,), dtype=int32)\n",
            "tf.Tensor([1 0 0 0 0], shape=(5,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get it all together"
      ],
      "metadata": {
        "id": "UQoVy0KcZTS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_training_data(sequences, window_size, num_ns, vocab_size):\n",
        "  # Elements of each training example are appended to these lists.\n",
        "    targets, contexts, labels = [], [], []\n",
        "\n",
        "  # Iterate over all sequences (sentences) in dataset.\n",
        "    for sequence in tqdm.tqdm(sequences):\n",
        "      skip_grams, sg_labels = tf.keras.preprocessing.sequence.skipgrams(\n",
        "          sequence,\n",
        "          vocabulary_size=vocab_size,\n",
        "          sampling_table=None,\n",
        "          window_size=window_size,\n",
        "          negative_samples=num_ns)\n",
        "\n",
        "      positive_skip_grams = [skip_gram for idx, skip_gram in enumerate(skip_grams) if sg_labels[idx]==1]\n",
        "      negative_skip_grams = [skip_gram for idx, skip_gram in enumerate(skip_grams) if sg_labels[idx]==0]\n",
        "\n",
        "      # Iterate over every positive skipgram\n",
        "      for target_word, context_word in positive_skip_grams:\n",
        "        # Get negative skipgrams corresponding to the current positive skipgram\n",
        "        negative_skip_grams_candidates = [skip_gram for skip_gram in negative_skip_grams if\n",
        "                                          skip_gram[0]==target_word]\n",
        "        current_negative_skip_grams = negative_skip_grams_candidates[:num_ns]\n",
        "        # remove selected negative skipgrams from negative_skip_grams list\n",
        "        for skip_gram in current_negative_skip_grams:\n",
        "          negative_skip_grams.remove(skip_gram)\n",
        "\n",
        "        target = tf.squeeze(target_word)\n",
        "        context = tf.squeeze([context_word] + [x[1] for x in current_negative_skip_grams] )\n",
        "        label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
        "\n",
        "        targets.append(target_word)\n",
        "        contexts.append(context)\n",
        "        labels.append(label)\n",
        "\n",
        "    return targets, contexts, labels"
      ],
      "metadata": {
        "id": "Qb_0TOMhaa0l"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets, contexts, labels = generate_training_data([example_sequence], window_size, num_ns, 10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ7jtdZvaa3Y",
        "outputId": "2cc62a7f-b559-4ba8-9d73-13484e2da581"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 66.96it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at the contexts. First element is right context and the others are wrong context (negative sampling)"
      ],
      "metadata": {
        "id": "G2BN99VyUBX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contexts[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_JytVxplGFJ",
        "outputId": "4e0c1378-c790-40b4-c009-86189e5da5f8"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(5,), dtype=int32, numpy=array([   7, 2447, 5627,  481, 6719], dtype=int32)>,\n",
              " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([   8, 4742, 8095, 1291, 4478], dtype=int32)>,\n",
              " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([   2, 7624, 4307, 2855, 3858], dtype=int32)>,\n",
              " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([   7, 6771, 5063, 4853, 2018], dtype=int32)>,\n",
              " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([   6, 6604, 6162, 9023, 3908], dtype=int32)>,\n",
              " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([   7, 5774, 1103, 3556, 9772], dtype=int32)>,\n",
              " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([   6, 7883, 9710, 1036, 4964], dtype=int32)>,\n",
              " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([   4, 9032, 9370, 4030, 7450], dtype=int32)>,\n",
              " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([   4, 3102,   55, 2041, 8935], dtype=int32)>,\n",
              " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([   3, 1094, 5071, 9249, 3267], dtype=int32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "685iH2rSlmPm",
        "outputId": "b8a4a5e5-b255-4135-f27f-7bbc51c84f9b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 0, 0, 0, 0])>,\n",
              " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 0, 0, 0, 0])>,\n",
              " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 0, 0, 0, 0])>,\n",
              " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 0, 0, 0, 0])>,\n",
              " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 0, 0, 0, 0])>,\n",
              " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 0, 0, 0, 0])>,\n",
              " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 0, 0, 0, 0])>,\n",
              " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 0, 0, 0, 0])>,\n",
              " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 0, 0, 0, 0])>,\n",
              " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 0, 0, 0, 0])>]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets = np.array(targets)\n",
        "contexts = np.array(contexts)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print('\\n')\n",
        "print(f\"targets.shape: {targets.shape}\")\n",
        "print(f\"contexts.shape: {contexts.shape}\")\n",
        "print(f\"labels.shape: {labels.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E0A-BVfdMB1",
        "outputId": "118c1e57-091e-47c7-ed6b-14e5fbda1098"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "targets.shape: (30,)\n",
            "contexts.shape: (30, 5)\n",
            "labels.shape: (30, 5)\n"
          ]
        }
      ]
    }
  ]
}